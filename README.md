# ğŸš€ RL-VOCASET 

ì´ ì €ì¥ì†ŒëŠ” RL-VOCASETì˜ ì „ì²´ ì½”ë“œ, Docker í™˜ê²½, Checkpoint ë‹¤ìš´ë¡œë“œ ë§í¬,  
ê·¸ë¦¬ê³  í•™ìŠµ ë° ì¶”ë¡  ë°©ë²•ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.  

> âš ï¸ **ì£¼ì˜:** ì´ ì €ì¥ì†ŒëŠ” ì§ì ‘ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”!  
> ì‘ì—… ì‹œ ë°˜ë“œì‹œ **Fork** í›„ ê°œì¸ ì €ì¥ì†Œì—ì„œ ì§„í–‰í•˜ì„¸ìš”.
---

# ğŸ’ª TODO List  
- [X] style(codetalker, faceformer), no-style(selftalk) ì´í•´ ë° Metric
- [ ] Add Codetalker
- [ ] Checkpoints Huggingface upload
- [ ] Datasets Huggingface Upload
- [ ] Reinforcement Learning Optimization (PPO)
- [ ] Reinforcement Learning Optimization (GRPO)
- [ ] Reward Model Dataset build Code
- [ ] Reward Model Training Code
- [ ] Reward Model ê°œì„ 


## ğŸ“˜ 1. GitHub ì‚¬ìš©ë²•

### ğŸ”¹ ì €ì¥ì†Œ Fork ë° Clone
1. ìƒë‹¨ì˜ **Fork** ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ê°œì¸ ê³„ì •ìœ¼ë¡œ ë³µì œí•©ë‹ˆë‹¤.
2. Forkëœ ì €ì¥ì†Œì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¡œ í´ë¡ í•©ë‹ˆë‹¤.
   ```bash
   git clone https://github.com/<your-username>/RL-VOCA.git

## ğŸ“˜ 2. Environment Setting
   ```bash
   docker pull esh0504/project:RL-VOCASET
   docker run -it --gpus all -v RL-VOCASET:/workspace -v /data/vocaset:/data/vocaset esh0504/project:RL-VOCA
   ```
## ğŸ“˜ 3. Reward Model Checkpoints
- encoder: [link](https://drive.google.com/file/d/10bYZp4-O23HFdriY7AfF3iYn8LH5vOfn/view?usp=drive_link)
- head: [link](https://drive.google.com/file/d/1V4yeorO4buESqAnwnzow9dddRrKyLXA6/view?usp=drive_link)

## ğŸ“˜ 4. Train (you can setting your config file (in configs/config.yaml).
python main.py

