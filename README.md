```markdown
# RL-project
```
```
> ì´ ì €ì¥ì†ŒëŠ” **ê¸°ìˆ  ê³µê°œ ë²”ìœ„ë¥¼ ìµœì†Œí™”í•œ ë°ëª¨ìš© êµ¬ì¡°(skeleton)**ì…ë‹ˆë‹¤.  
> ì‹¤ì œ ëª¨ë¸, í•™ìŠµ ì½”ë“œ, ì²´í¬í¬ì¸íŠ¸, ë°ì´í„°ì…‹ì€ **í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.**  
> ë³¸ ë¬¸ì„œëŠ” **ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´í•´**ë¥¼ ìœ„í•œ ìš”ì•½ì´ë©°,  
> ì„¸ë¶€ êµ¬ì¡°Â·ì°¨ì›Â·ì•Œê³ ë¦¬ì¦˜ì€ ì—°êµ¬ ë³´í˜¸ë¥¼ ìœ„í•´ ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
```


#  ğŸ® Speech-to-3D Face Animation 

## âœ…1. Overview
<img width="1345" height="479" alt="image" src="https://github.com/user-attachments/assets/eb7943ce-6e47-4447-a66b-6fff0682a755" />




## âœ…2. Project Goals
([ğŸ”— : ë°œí‘œìë£Œ](https://www.canva.com/design/DAG6h43SCnU/Bg0qUI8bYz8JZkyo-mPMCg/edit?utm_content=DAG6h43SCnU&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton) )


ë³¸ í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œëŠ” ì…ë ¥ ìŒì„±ì— ë§ì¶”ì–´ ìì—°ìŠ¤ëŸ½ê²Œ ì›€ì§ì´ëŠ” 3D ì–¼êµ´ ë©”ì‰¬/ì˜ìƒì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë‹¨ìˆœíˆ vertex ìœ„ì¹˜ ì˜¤ì°¨(MSE)ë¥¼ ì¤„ì´ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì‚¬ëŒì´ ëŠë¼ëŠ” ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—,
ë³¸ ì—°êµ¬ëŠ” **ì§€ê°ì  í’ˆì§ˆ(perceptual quality)**ì„ ìµœìš°ì„ ìœ¼ë¡œ ë‘” í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

##### âœ” ì •ëŸ‰ì  ì˜¤ì°¨ ìµœì†Œí™”(MSE, L2) ìì²´ê°€ ëª©ì ì´ ì•„ë‹ˆë¼,

##### âœ” ì‚¬ëŒì´ ë³´ì•˜ì„ ë•Œ 'ìì—°ìŠ¤ëŸ½ë‹¤'ê³  ëŠë¼ëŠ” ì…ëª¨ì–‘, ì–¼êµ´ ì›€ì§ì„, íƒ€ì´ë°, í‘œí˜„ë ¥

ì„ ìƒì„±í•˜ëŠ” ë° ì´ˆì ì„ ë‘¡ë‹ˆë‹¤.
ì´ë¥¼ ìœ„í•´ Actor ëª¨ë¸(FaceFormer)ì˜ ì¶œë ¥ì— ëŒ€í•´
Reward ëª¨ë¸ì„ í™œìš©í•˜ì—¬ lip realismÂ·motion naturalness ê¸°ë°˜ì˜ ê°•í™”í•™ìŠµ ì‹ í˜¸ë¥¼ ë¶€ì—¬í•¨ìœ¼ë¡œì¨,
ì •í™•ë„ ì¤‘ì‹¬ì˜ supervised learningì„ ë„˜ì–´ ë” ì‚¬ëŒë‹¤ìš´(face-like) ì›€ì§ì„ì„ í•™ìŠµí•˜ë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.





## âœ… 3.Main íŒŒì´í”„ë¼ì¸ íë¦„ ë° ìš”ì•½ (`/workspace/RL-VOCASET/main.py` ê¸°ì¤€)

1) **Hydra ì„¤ì • ë¡œë“œ**  
   - `configs/config.yaml` ê¸°ë³¸ê°’: model=faceformer, dataset=style, trainer=faceformer
2) **ë°ì´í„° ë¡œë” ì¤€ë¹„**  
   - `dataset/dataloader_style.py` ë¡œ wav â†’ mel, vertices, template ë¡œë“œ
3) **Actor ëª¨ë¸ ë¹Œë“œ**  
   - `models/faceformer/model.py` (ì˜¤ë””ì˜¤ ì¸ì½”ë” `models/wav2vec.py` í¬í•¨)
4) **Reward ë°±ë³¸/í—¤ë“œ ë¡œë“œ**  
   - `models/reward/models/modeling.py` (SpeechMeshTransformer)  
   - `models/reward/models/head_v2.py` (lip/real/value í—¤ë“œ)
5) **í•™ìŠµ ë£¨í”„**  
   - `trainer/faceformer/trainer.py`ì—ì„œ sup loss + RL(actor/critic) ì¡°í•© í•™ìŠµ
6) **í…ŒìŠ¤íŠ¸**  
   - ê°™ì€ íŠ¸ë ˆì´ë„ˆì—ì„œ style-dependent í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
7) **ì €ì¥**  
   - `checkpoints/{wandb_name}/best.pt` ë“±ì— ëª¨ë¸/í—¤ë“œ ì €ì¥
      - 
   ###  1) Main Workflow Summary (`python main.py`)
   ëª¨ë¸ì„ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ íŒŒì´í”„ë¼ì¸ì´ ì§„í–‰ë©ë‹ˆë‹¤.
   
   Config ë¡œë“œ â†’ ë°ì´í„° ì¤€ë¹„ â†’ Actor ëª¨ë¸ ì¶”ë¡  â†’ Reward í‰ê°€ â†’ RL í•™ìŠµ â†’ Validation/Test
   
   ê° ê³¼ì •ì˜ ëª©ì ë§Œ ì„¤ëª…í•˜ë©° **êµ¬ì²´ì ì¸ êµ¬í˜„, ìˆ˜ì‹, ì°¨ì› ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
   
   ---
   
   ### 2) ğŸ”§ Config & Environment Loading
   - Hydra ê¸°ë°˜ ì„¤ì • ë¡œë”©
   - ëª¨ë¸ ì¢…ë¥˜, ë°ì´í„°ì…‹ íƒ€ì…, í•™ìŠµ/í‰ê°€ ì˜µì…˜ì„ í¬í•¨í•œ high-level configuration
   - ì‹¤ì œ training parameter, architecture detailì€ ë¹„ê³µê°œ
   
   ---
   
   ### 3) ğŸ§ Data Loader (Audio & Mesh Preparation)
   ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
   
   ##### í¬í•¨ ìš”ì†Œ
   - **ìŒì„± ì‹ í˜¸**  
     - waveform â†’ ìŒì„± ì¸ì½”ë”ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” embeddingìœ¼ë¡œ ë³€í™˜
   - **ë©œ ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§•**  
     - Reward ëª¨ë¸ì—ì„œ í’ˆì§ˆ í‰ê°€ì— ì°¸ê³ ë˜ëŠ” ë³´ì¡° ì˜¤ë””ì˜¤ í‘œí˜„
   - **Template Mesh**  
     - í•œ ì–¼êµ´ templateì— ëŒ€í•´ displacementë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹
   - **Ground Truth Mesh Sequence**  
     - time-aligned mesh ì‹œí€€ìŠ¤
   - **Subject Embedding**  
     - í™”ì ì¡°ê±´ ë¶€ì—¬(ì›í•« or ì„ë² ë”©)
   
   ##### ë¹„ê³µê°œ ìš”ì†Œ
   - ë°ì´í„° ì°¨ì› ë° ë‚´ë¶€ ì „ì²˜ë¦¬ ë¡œì§
   - wav2vec/mesh loader ë“±ì˜ êµ¬ì²´ êµ¬í˜„
   
   ---
   
   ### 4) ğŸ§‘â€ğŸ« Actor Model (Face Animation Generator)
   Actor ëª¨ë¸ì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
   
   ##### ëª¨ë¸ ì—­í• 
   - ìŒì„± ì¸ì½”ë”ê°€ ì¶”ì¶œí•œ speech embeddingê³¼  
     template mesh Â· subject ì •ë³´ ë“±ì„ ê²°í•©í•˜ì—¬  
     **íƒ€ì„ë¼ì¸ì— ë”°ë¥¸ 3D ì–¼êµ´ ë©”ì‰¬ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤.
   
   
   ##### ë¹„ê³µê°œ(ì—°êµ¬ ë³´í˜¸) ì²˜ë¦¬
   - ì¸ì½”ë” êµ¬ì¡°, ì°¨ì›, attention/bias êµ¬ì¡°, normalization ë°©ì‹
   - mesh representation ì°¨ì›
   - distribution ê¸°ë°˜ sampling ê³µì‹
   - loss functionì˜ êµ¬ì²´ì ì¸ ì¡°í•© ë° ê³„ì‚° ê³¼ì •
   
   ---
   
   ### 5) â­ Reward Model (Freezeëœ í’ˆì§ˆ í‰ê°€ ë„¤íŠ¸ì›Œí¬)
   í•™ìŠµ ì‹œ actorê°€ ìƒì„±í•œ meshë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ **ë³„ë„ì˜ í’ˆì§ˆ ì¸¡ì • ëª¨ë¸**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
   
   ##### ê¸°ëŠ¥
   - ì˜¤ë””ì˜¤â€“ë©”ì‰¬ ê°„ **lip-sync**, **realism** ë“±ì„ ì¸¡ì •  
   - freeze ìƒíƒœë¡œ ì‚¬ìš©ë˜ë©°, actor ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ rewardë¥¼ ì œê³µ
   
   ##### ë¹„ê³µê°œ ì²˜ë¦¬
   - backbone/score-head architecture  
   - ì…ë ¥ clip í˜•ì‹, ì°¨ì›  
   - score ê³„ì‚° ë°©ì‹  
   
   ---
   
   ### 6) ğŸ§  Reinforcement Learning Loop (High-Level Description Only)
   ë³¸ í”„ë¡œì íŠ¸ëŠ” supervised lossì™€ reinforcement signalì„ í•¨ê»˜ ì‚¬ìš©í•©ë‹ˆë‹¤.
   
   ##### ì „ì²´ íë¦„
   1) Actorê°€ ì˜ˆì¸¡ ë©”ì‰¬ ìƒì„±  
   2) Reward ëª¨ë¸ì´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°  
   3) Criticì´ ì˜ˆì¸¡ ì•ˆì •ì„±ì„ ë•ëŠ” ë°©í–¥ìœ¼ë¡œ í‰ê°€  
   4) ActorëŠ” ë†’ì€ í’ˆì§ˆ ë°©í–¥ìœ¼ë¡œ ì—…ë°ì´íŠ¸  
   5) Criticì€ rewardë¥¼ ë” ì˜ ì˜ˆì¸¡í•˜ë„ë¡ ì—…ë°ì´íŠ¸  
   6) Supervised í•™ìŠµê³¼ RL ì‹ í˜¸ê°€ í•¨ê»˜ ìµœì¢… loss êµ¬ì„±
   
   ##### ë¹„ê³µê°œ ì²˜ë¦¬
   - advantage ê³„ì‚°ì‹  
   - actor/critic loss ê³µì‹  
   - weight/scale ê°’  
   - log_prob ê¸°ë°˜ ì •ì±… ì—…ë°ì´íŠ¸ ë°©ì‹  
   
   ---
   
   ### 7) ğŸ§ª Validation
   - baseline model(faceformer)ê°€ meshë¥¼ ìƒì„±í•˜ì—¬ í’ˆì§ˆ ì§€í‘œë¥¼ ê¸°ë¡  
   
   
   ---
   
   ### 8) ğŸ§« Test / Inference (Demo Version)
   - best checkpointê°€ ì£¼ì–´ì§ˆ ê²½ìš° ì „ì²´ subject ì¡°ê±´ì—ì„œ ë©”ì‰¬ ìƒì„±  
   - ê²°ê³¼ëŠ” .npy ë¡œ ì €ì¥ ê°€ëŠ¥  
   - public repoì—ëŠ” checkpointê°€ í¬í•¨ë˜ì§€ ì•ŠìŒìŒ
   
   ---
   
   ##### ğŸš« í¬í•¨ë˜ì§€ ì•ŠëŠ” í•­ëª© (Important)
   ë³¸ ê³µê°œ ë²„ì „ì—ëŠ” ì•„ë˜ íŒŒì¼/êµ¬í˜„ì´ ì ˆëŒ€ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
   
   - ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ weight (*.pt, *.pth)
   - wav2vec ê¸°ë°˜ ìŒì„± ì¸ì½”ë” êµ¬í˜„
   - mesh reconstruction/decoder ë‚´ë¶€ êµ¬ì¡°
   - reward backbone ë° score head ìƒì„¸ êµ¬ì¡°
   - reinforcement learning ê³µì‹, weighting, optimizer ì„¸ë¶€ ë¡œì§
   - ë°ì´í„°ì…‹(wav, mel, vertices, template, mask)
   - mask index, facial region mapping ë“± research-critical ì •ë³´
   - ë…¼ë¬¸ êµ¬í˜„ê³¼ ì§ì ‘ ì—°ê²°ë˜ëŠ” ì°¨ì›/ìˆ˜ì‹/ì•Œê³ ë¦¬ì¦˜
   
   ---

## ğŸ“ 4.Repository Structure (Demo Skeleton)
```
RL-VOCASET/
â”œâ”€â”€ checkpoints/              # (ë¹„ì–´ ìˆìŒ) ì‹¤ì œ ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒ
â”œâ”€â”€ configs/                  # Hydra ê¸°ë°˜ ì„¤ì • íŒŒì¼ êµ¬ì¡°
â”‚   â”œâ”€â”€ dataset/              # ë°ì´í„° ë¡œë”© ê´€ë ¨ ì˜µì…˜ 
â”‚   â”œâ”€â”€ model/                # ëª¨ë¸ ì„¤ì • placeholder
â”‚   â”œâ”€â”€ trainer/              # í•™ìŠµ/í‰ê°€ ì„¤ì • placeholder
â”‚   â””â”€â”€ config.yaml           # ê¸°ë³¸ ì—”íŠ¸ë¦¬ ì„¤ì •
â”œâ”€â”€ dataset/                  # VOCASET ìŠ¤íƒ€ì¼ ë°ì´í„° ë¡œë” ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ models/                   # ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¡°
â”‚   â”œâ”€â”€ faceformer/           # Actor(ìƒì„± ëª¨ë¸) ì¸í„°í˜ì´ìŠ¤(ì˜¤ë””ì˜¤ â†’ ë©”ì‰¬).
â”‚   â””â”€â”€ reward/               # Reward í‰ê°€ ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ src/                     
â”œâ”€â”€ trainer/                  # í•™ìŠµ/ê²€ì¦/í‰ê°€ íë¦„ skeleton
â”œâ”€â”€ utils/                    
â”œâ”€â”€ vocaset/                  # (ë¹„ì–´ ìˆìŒ) ì‹¤ì œ ë°ì´í„° í¬í•¨ë˜ì§€ ì•ŠìŒ
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py                   # Hydra ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
â”œâ”€â”€ README.md
â”œâ”€â”€ render.py                 # ê²°ê³¼ ë Œë”ë§/ì‹œê°í™”ìš© placeholder
â””â”€â”€ reward_score.py           # Reward ê³„ì‚° 

```






### ğŸ“Œ Notes for Reviewers / Collaborators

* ë³¸ ë¬¸ì„œëŠ” ì—°êµ¬ íŒŒì´í”„ë¼ì¸ ì„¤ëª…ìš© ë¬¸ì„œì´ë©°,
ì‹¤ì œ ëª¨ë¸ì„ ì¬í˜„í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

* ìš”ì²­ ì‹œ full versionì€ private ì €ì¥ì†Œ ë° ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œë§Œ ê³µìœ ë©ë‹ˆë‹¤.

* ë³¸ repoëŠ” í•™ìŠµ/í‰ê°€ ì‹¤í–‰ì´ ë¶ˆê°€ëŠ¥í•˜ë©°, êµ¬ì¡° ì´í•´ì™€ ë°ëª¨ ëª©ì ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.











---
ì´ê±°ëŠ” ë¹¼ì•¼í• ë“¯.
```bash
### 1) ğŸ”§ Config ë¡œë“œ (Hydra)
 - configs/config.yaml ë¶ˆëŸ¬ì˜¤ê¸°
 - defaults:
     model: faceformer
     dataset: style
     trainer: faceformer
 - cfg.train / cfg.test í”Œë˜ê·¸ì— ë”°ë¼ í•™ìŠµÂ·í‰ê°€ ì‹¤í–‰


### 2) ë°ì´í„° ë¡œë”© â€” dataset/dataloader_style.py
 -------------------------------------------------
- WAV ë¡œë“œ â†’ Wav2Vec2Processor ì…ë ¥ê°’ ìƒì„±
audio: (T_audio, )

- Mel íŠ¹ì§•(rep_audio_mel) â€” Reward ëª¨ë¸ìš©
rep_audio_mel: (T_clip, 1, 20, 128)

- Template mesh
template: (5023, 3) â†’ flatten â†’ (15069,)

- GT vertex ì‹œí€€ìŠ¤ (2í”„ë ˆì„ ìƒ˜í”Œë§ ì ìš©)
vertice: (seq_len, 15069)

- Subject one-hot
one_hot_train:     (num_speakers,)
one_hot_val_test:  (num_speakers_all, num_speakers)

- DataLoader ë°°ì¹˜ (batch=1)
batch_audio:   (1, T_audio)
batch_vertice: (1, seq_len, 15069)
batch_template:(1, 15069)
batch_onehot:  (1, num_speakers)
batch_rep_mel: rep_audio_mel ê·¸ëŒ€ë¡œ


### 3) Actor Model (FaceFormer) â€” models/faceformer/model.py
 -----------------------------------------------------------
- Audio Encoder
wav2vec2 â†’ (1, T_audio', 768) â†’ Linear â†’ (1, T_audio', 64)

- Transformer Decoder ì…ë ¥:
 - template displacement
 - style embedding(one_hot)
 - PPE, temporal bias ë“± í¬í•¨

- ì¶œë ¥:
vertice_mu:     (1, seq_len, 15069)     # mean
vertice_sample: (1, seq_len, 15069)     # stochastic modeì¼ ë•Œ
dist: Normal(Î¼,Ïƒ)                       # log_prob ê³„ì‚°ìš©

- Supervised Loss:
sup_loss = MSE(pred, GT)


### 4) Reward Backbone (ê³ ì •) â€” SpeechMeshTransformer
 ---------------------------------------------------
- ì…ë ¥:
mesh_clip: (B, 5, 15069)
mel_clip:  (B, 1, 20, 128)

- ì¶œë ¥ ì„ë² ë”©:
vertex_feat: (B, 512)
audio_feat:  (B, 512)

- ckpt ë¡œë“œ í›„ freeze, eval ëª¨ë“œ.


### 5) Score Head â€” head_v2.py
 --------------------------------
- ì…ë ¥:
concat_feat: (B, 512 + 512)

- ì¶œë ¥:
lip_score:  (B,)    # sigmoid
real_score: (B,)    # sigmoid
value:      (B,)    # critic V(s)

 head ckptëŠ” í•™ìŠµ ëŒ€ìƒ (requires_grad=True)


### 6) í•™ìŠµ ë£¨í”„ â€” trainer/faceformer/trainer.py::train
 ------------------------------------------------------

 (1) Actor forward
vertice_mu, vertice_sample, sup_loss

 (2) Reward ê³„ì‚°
 rep_audio_mel â†’ 5í”„ë ˆì„ ë‹¨ìœ„ ìŠ¬ë¼ì´ë”© â†’ backbone â†’ head
lip, real, value = mean over clips

reward    = (lip + real) * reward_scale
advantage = reward - value

actor_loss  = -advantage * mean(log_prob(sample))     # stochasticì¸ ê²½ìš°
critic_loss = (reward - value) ** 2

total_loss = sup_loss \
           + actor_weight  * actor_loss \
           + critic_weight * critic_loss

 Optimizer: Actor + Head ì—…ë°ì´íŠ¸


### 7) Validation
 ------------------------------------------------------
 - Actor deterministic forward
 - LVE(mouth vertex error) ê³„ì‚°
 - best ì„±ëŠ¥ ì‹œ ckpt ì €ì¥:
     checkpoints/<wandb_name>/best.pt
     checkpoints/<wandb_name>/best_head.pt


### 8) Test â€” trainer/faceformer/trainer.py::test
 ------------------------------------------------------
 - best ckpt ë¡œë“œ
 - ëª¨ë“  subject one-hot ì¡°ê±´ë³„ë¡œ ì˜ˆì¸¡ mesh npy ì €ì¥:
   checkpoints/<wandb_name>/styledependant/results/*.npy
 - LVE / FDD ê³„ì‚° ì¶œë ¥
 - style-independent ëª¨ë“œ: ëª¨ë“  one-hot í‰ê· ê°’ ì‚¬ìš©



## í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²ƒ
- ì‹¤ì œ í•™ìŠµ/ì¶”ë¡  êµ¬í˜„ ìƒì„¸, RL/Reward ë‚´ë¶€ ë¡œì§
- ì²´í¬í¬ì¸íŠ¸(.pt), ë°ì´í„°(wav, mel npy, vertices npy, templates, masks)

## ì‹¤ì œ ë°ì´í„°/ì²´í¬í¬ì¸íŠ¸ë¥¼ ì“¸ ê²½ìš° í•„ìš”í•œ ê²½ë¡œ (ì°¸ê³ ìš©)
 ì˜¤ë””ì˜¤: `vocaset/wav/`  
- ë©œ ìŠ¤í™íŠ¸ëŸ¼: `vocaset/wav_npy/`  
- ë©”ì‰¬ GT: `vocaset/vertices_npy/`  
- í…œí”Œë¦¿/ë§ˆìŠ¤í¬: `vocaset/templates.pkl`, `vocaset/FLAME_masks.pkl`  
- ë¦¬ì›Œë“œ ë°±ë³¸/í—¤ë“œ ckpt: `checkpoints/reward/model_loss.pth`, `checkpoints/reward/v4_best.pt`  
ë°ëª¨ ë¦¬í¬ì—ëŠ” ìœ„ íŒŒì¼ì´ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

```




