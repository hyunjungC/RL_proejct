```markdown
# RL-project
```

#  ğŸ® FaceFormer ê°•í™”í•™ìŠµ í”„ë¡œì íŠ¸ 

ë³¸ í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œëŠ” ì…ë ¥ ìŒì„±ì— ë§ì¶”ì–´ ìì—°ìŠ¤ëŸ½ê²Œ ì›€ì§ì´ëŠ” 3D ì–¼êµ´ ë©”ì‰¬/ì˜ìƒì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë‹¨ìˆœíˆ vertex ìœ„ì¹˜ ì˜¤ì°¨(MSE)ë¥¼ ì¤„ì´ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì‚¬ëŒì´ ëŠë¼ëŠ” ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—,
ë³¸ ì—°êµ¬ëŠ” **ì§€ê°ì  í’ˆì§ˆ(perceptual quality)**ì„ ìµœìš°ì„ ìœ¼ë¡œ ë‘” í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

##### âœ” ì •ëŸ‰ì  ì˜¤ì°¨ ìµœì†Œí™”(MSE, L2) ìì²´ê°€ ëª©ì ì´ ì•„ë‹ˆë¼,

##### âœ” ì‚¬ëŒì´ ë³´ì•˜ì„ ë•Œ 'ìì—°ìŠ¤ëŸ½ë‹¤'ê³  ëŠë¼ëŠ” ì…ëª¨ì–‘, ì–¼êµ´ ì›€ì§ì„, íƒ€ì´ë°, í‘œí˜„ë ¥

ì„ ìƒì„±í•˜ëŠ” ë° ì´ˆì ì„ ë‘¡ë‹ˆë‹¤.
ì´ë¥¼ ìœ„í•´ Actor ëª¨ë¸(FaceFormer)ì˜ ì¶œë ¥ì— ëŒ€í•´
Reward ëª¨ë¸ì„ í™œìš©í•˜ì—¬ lip realismÂ·motion naturalness ê¸°ë°˜ì˜ ê°•í™”í•™ìŠµ ì‹ í˜¸ë¥¼ ë¶€ì—¬í•¨ìœ¼ë¡œì¨,
ì •í™•ë„ ì¤‘ì‹¬ì˜ supervised learningì„ ë„˜ì–´ ë” ì‚¬ëŒë‹¤ìš´(face-like) ì›€ì§ì„ì„ í•™ìŠµí•˜ë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.


```bash
âœ…
```

## âœ…íŒŒì¼ ì—­í•  (í•µì‹¬ ì‹œê·¸ë‹ˆì²˜ë§Œ ë…¸ì¶œ)
```bash
- `main.py` : Hydra ì—”íŠ¸ë¦¬. config ì½ê³  ë°ì´í„°ë¡œë”/ëª¨ë¸/ë¦¬ì›Œë“œ/íŠ¸ë ˆì´ë„ˆ ê°ì²´ë¥¼ ì—®ì–´ train/test ì‹¤í–‰.
- `dataset/dataloader_style.py` : VOCASET ìŠ¤íƒ€ì¼ ë°ì´í„° ë¡œë” ì¸í„°í˜ì´ìŠ¤.
- `models/faceformer/model.py` : FaceFormer ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤(ì˜¤ë””ì˜¤ â†’ ë©”ì‰¬).
- `models/wav2vec.py` : Wav2Vec2 ì˜¤ë””ì˜¤ ì¸ì½”ë” ë˜í¼ ì¸í„°í˜ì´ìŠ¤.
- `models/reward/models/modeling.py` : SpeechMeshTransformer ë°±ë³¸ ì¸í„°í˜ì´ìŠ¤.
- `models/reward/models/head_v2.py` : Reward/critic í—¤ë“œ ì¸í„°í˜ì´ìŠ¤.
- `trainer/faceformer/trainer.py` : í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë§Œ ë‚¨ê¸´ íŠ¸ë ˆì´ë„ˆ.
- `src/utils.py` : ê³µìš© ìœ í‹¸(ë¡œê¹… ë“±).
```


## âœ…ì‹¤ì œ íŒŒì´í”„ë¼ì¸ íë¦„ ( `/workspace/RL-VOCASET_my_copy_check_3/main.py` ê¸°ì¤€ )
1) **Hydra ì„¤ì • ë¡œë“œ**  
   - `configs/config.yaml` ê¸°ë³¸ê°’: model=faceformer, dataset=style, trainer=faceformer
2) **ë°ì´í„° ë¡œë” ì¤€ë¹„**  
   - `dataset/dataloader_style.py` ë¡œ wav â†’ mel, vertices, template ë¡œë“œ
3) **Actor ëª¨ë¸ ë¹Œë“œ**  
   - `models/faceformer/model.py` (ì˜¤ë””ì˜¤ ì¸ì½”ë” `models/wav2vec.py` í¬í•¨)
4) **Reward ë°±ë³¸/í—¤ë“œ ë¡œë“œ**  
   - `models/reward/models/modeling.py` (SpeechMeshTransformer)  
   - `models/reward/models/head_v2.py` (lip/real/value í—¤ë“œ)
5) **í•™ìŠµ ë£¨í”„**  
   - `trainer/faceformer/trainer.py`ì—ì„œ sup loss + RL(actor/critic) ì¡°í•© í•™ìŠµ
6) **í…ŒìŠ¤íŠ¸**  
   - ê°™ì€ íŠ¸ë ˆì´ë„ˆì—ì„œ style-dependent í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
7) **ì €ì¥**  
   - `checkpoints/{wandb_name}/best.pt` ë“±ì— ëª¨ë¸/í—¤ë“œ ì €ì¥




##  âœ…Main íŒŒì´í”„ë¼ì¸ ìš”ì•½ (ë°ì´í„° ì°¨ì› í¬í•¨)

## `python main.py` ì‹¤í–‰ ì‹œ ì „ì²´ íë¦„:

### 1) ğŸ”§ Config ë¡œë“œ (Hydra)
 - configs/config.yaml ë¶ˆëŸ¬ì˜¤ê¸°
 - defaults:
     model: faceformer
     dataset: style
     trainer: faceformer
 - cfg.train / cfg.test í”Œë˜ê·¸ì— ë”°ë¼ í•™ìŠµÂ·í‰ê°€ ì‹¤í–‰


### 2) ë°ì´í„° ë¡œë”© â€” dataset/dataloader_style.py
 -------------------------------------------------
- WAV ë¡œë“œ â†’ Wav2Vec2Processor ì…ë ¥ê°’ ìƒì„±
audio: (T_audio, )

- Mel íŠ¹ì§•(rep_audio_mel) â€” Reward ëª¨ë¸ìš©
rep_audio_mel: (T_clip, 1, 20, 128)

- Template mesh
template: (5023, 3) â†’ flatten â†’ (15069,)

- GT vertex ì‹œí€€ìŠ¤ (2í”„ë ˆì„ ìƒ˜í”Œë§ ì ìš©)
vertice: (seq_len, 15069)

- Subject one-hot
one_hot_train:     (num_speakers,)
one_hot_val_test:  (num_speakers_all, num_speakers)

- DataLoader ë°°ì¹˜ (batch=1)
batch_audio:   (1, T_audio)
batch_vertice: (1, seq_len, 15069)
batch_template:(1, 15069)
batch_onehot:  (1, num_speakers)
batch_rep_mel: rep_audio_mel ê·¸ëŒ€ë¡œ


### 3) Actor Model (FaceFormer) â€” models/faceformer/model.py
 -----------------------------------------------------------
- Audio Encoder
wav2vec2 â†’ (1, T_audio', 768) â†’ Linear â†’ (1, T_audio', 64)

- Transformer Decoder ì…ë ¥:
 - template displacement
 - style embedding(one_hot)
 - PPE, temporal bias ë“± í¬í•¨

- ì¶œë ¥:
vertice_mu:     (1, seq_len, 15069)     # mean
vertice_sample: (1, seq_len, 15069)     # stochastic modeì¼ ë•Œ
dist: Normal(Î¼,Ïƒ)                       # log_prob ê³„ì‚°ìš©

- Supervised Loss:
sup_loss = MSE(pred, GT)


### 4) Reward Backbone (ê³ ì •) â€” SpeechMeshTransformer
 ---------------------------------------------------
- ì…ë ¥:
mesh_clip: (B, 5, 15069)
mel_clip:  (B, 1, 20, 128)

- ì¶œë ¥ ì„ë² ë”©:
vertex_feat: (B, 512)
audio_feat:  (B, 512)

- ckpt ë¡œë“œ í›„ freeze, eval ëª¨ë“œ.


### 5) Score Head â€” head_v2.py
 --------------------------------
- ì…ë ¥:
concat_feat: (B, 512 + 512)

- ì¶œë ¥:
lip_score:  (B,)    # sigmoid
real_score: (B,)    # sigmoid
value:      (B,)    # critic V(s)

 head ckptëŠ” í•™ìŠµ ëŒ€ìƒ (requires_grad=True)


### 6) í•™ìŠµ ë£¨í”„ â€” trainer/faceformer/trainer.py::train
 ------------------------------------------------------

 (1) Actor forward
vertice_mu, vertice_sample, sup_loss

 (2) Reward ê³„ì‚°
 rep_audio_mel â†’ 5í”„ë ˆì„ ë‹¨ìœ„ ìŠ¬ë¼ì´ë”© â†’ backbone â†’ head
lip, real, value = mean over clips

reward    = (lip + real) * reward_scale
advantage = reward - value

actor_loss  = -advantage * mean(log_prob(sample))     # stochasticì¸ ê²½ìš°
critic_loss = (reward - value) ** 2

total_loss = sup_loss \
           + actor_weight  * actor_loss \
           + critic_weight * critic_loss

 Optimizer: Actor + Head ì—…ë°ì´íŠ¸


### 7) Validation
 ------------------------------------------------------
 - Actor deterministic forward
 - LVE(mouth vertex error) ê³„ì‚°
 - best ì„±ëŠ¥ ì‹œ ckpt ì €ì¥:
     checkpoints/<wandb_name>/best.pt
     checkpoints/<wandb_name>/best_head.pt


### 8) Test â€” trainer/faceformer/trainer.py::test
 ------------------------------------------------------
 - best ckpt ë¡œë“œ
 - ëª¨ë“  subject one-hot ì¡°ê±´ë³„ë¡œ ì˜ˆì¸¡ mesh npy ì €ì¥:
   checkpoints/<wandb_name>/styledependant/results/*.npy
 - LVE / FDD ê³„ì‚° ì¶œë ¥
 - style-independent ëª¨ë“œ: ëª¨ë“  one-hot í‰ê· ê°’ ì‚¬ìš©



## í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²ƒ
- ì‹¤ì œ í•™ìŠµ/ì¶”ë¡  êµ¬í˜„ ìƒì„¸, RL/Reward ë‚´ë¶€ ë¡œì§
- ì²´í¬í¬ì¸íŠ¸(.pt), ë°ì´í„°(wav, mel npy, vertices npy, templates, masks)

## ì‹¤ì œ ë°ì´í„°/ì²´í¬í¬ì¸íŠ¸ë¥¼ ì“¸ ê²½ìš° í•„ìš”í•œ ê²½ë¡œ (ì°¸ê³ ìš©)
 ì˜¤ë””ì˜¤: `vocaset/wav/`  
- ë©œ ìŠ¤í™íŠ¸ëŸ¼: `vocaset/wav_npy/`  
- ë©”ì‰¬ GT: `vocaset/vertices_npy/`  
- í…œí”Œë¦¿/ë§ˆìŠ¤í¬: `vocaset/templates.pkl`, `vocaset/FLAME_masks.pkl`  
- ë¦¬ì›Œë“œ ë°±ë³¸/í—¤ë“œ ckpt: `checkpoints/reward/model_loss.pth`, `checkpoints/reward/v4_best.pt`  
ë°ëª¨ ë¦¬í¬ì—ëŠ” ìœ„ íŒŒì¼ì´ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.






