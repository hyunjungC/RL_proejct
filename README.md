```markdown
# RL-project
```
```
> ì´ ì €ì¥ì†ŒëŠ” **ê¸°ìˆ  ê³µê°œ ë²”ìœ„ë¥¼ ìµœì†Œí™”í•œ ë°ëª¨ìš© êµ¬ì¡°(skeleton)**ì…ë‹ˆë‹¤.  
> ì‹¤ì œ ëª¨ë¸, í•™ìŠµ ì½”ë“œ, ì²´í¬í¬ì¸íŠ¸, ë°ì´í„°ì…‹ì€ **í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.**  
> ë³¸ ë¬¸ì„œëŠ” **ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´í•´**ë¥¼ ìœ„í•œ ìš”ì•½ì´ë©°,  
> ì„¸ë¶€ êµ¬ì¡°Â·ì°¨ì›Â·ì•Œê³ ë¦¬ì¦˜ì€ ì—°êµ¬ ë³´í˜¸ë¥¼ ìœ„í•´ ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
```


#  ğŸ® Speech-to-3D Face Animation


ë³¸ í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œëŠ” ì…ë ¥ ìŒì„±ì— ë§ì¶”ì–´ ìì—°ìŠ¤ëŸ½ê²Œ ì›€ì§ì´ëŠ” 3D ì–¼êµ´ ë©”ì‰¬/ì˜ìƒì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë‹¨ìˆœíˆ vertex ìœ„ì¹˜ ì˜¤ì°¨(MSE)ë¥¼ ì¤„ì´ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì‚¬ëŒì´ ëŠë¼ëŠ” ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—,
ë³¸ ì—°êµ¬ëŠ” **ì§€ê°ì  í’ˆì§ˆ(perceptual quality)**ì„ ìµœìš°ì„ ìœ¼ë¡œ ë‘” í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

##### âœ” ì •ëŸ‰ì  ì˜¤ì°¨ ìµœì†Œí™”(MSE, L2) ìì²´ê°€ ëª©ì ì´ ì•„ë‹ˆë¼,

##### âœ” ì‚¬ëŒì´ ë³´ì•˜ì„ ë•Œ 'ìì—°ìŠ¤ëŸ½ë‹¤'ê³  ëŠë¼ëŠ” ì…ëª¨ì–‘, ì–¼êµ´ ì›€ì§ì„, íƒ€ì´ë°, í‘œí˜„ë ¥

ì„ ìƒì„±í•˜ëŠ” ë° ì´ˆì ì„ ë‘¡ë‹ˆë‹¤.
ì´ë¥¼ ìœ„í•´ Actor ëª¨ë¸(FaceFormer)ì˜ ì¶œë ¥ì— ëŒ€í•´
Reward ëª¨ë¸ì„ í™œìš©í•˜ì—¬ lip realismÂ·motion naturalness ê¸°ë°˜ì˜ ê°•í™”í•™ìŠµ ì‹ í˜¸ë¥¼ ë¶€ì—¬í•¨ìœ¼ë¡œì¨,
ì •í™•ë„ ì¤‘ì‹¬ì˜ supervised learningì„ ë„˜ì–´ ë” ì‚¬ëŒë‹¤ìš´(face-like) ì›€ì§ì„ì„ í•™ìŠµí•˜ë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.

<img width="1345" height="479" alt="image" src="https://github.com/user-attachments/assets/eb7943ce-6e47-4447-a66b-6fff0682a755" />





##  âœ…Main íŒŒì´í”„ë¼ì¸ íë¦„ ë° ìš”ì•½ (`/workspace/RL-VOCASET/main.py` ê¸°ì¤€)

1) **Hydra ì„¤ì • ë¡œë“œ**  
   - `configs/config.yaml` ê¸°ë³¸ê°’: model=faceformer, dataset=style, trainer=faceformer
2) **ë°ì´í„° ë¡œë” ì¤€ë¹„**  
   - `dataset/dataloader_style.py` ë¡œ wav â†’ mel, vertices, template ë¡œë“œ
3) **Actor ëª¨ë¸ ë¹Œë“œ**  
   - `models/faceformer/model.py` (ì˜¤ë””ì˜¤ ì¸ì½”ë” `models/wav2vec.py` í¬í•¨)
4) **Reward ë°±ë³¸/í—¤ë“œ ë¡œë“œ**  
   - `models/reward/models/modeling.py` (SpeechMeshTransformer)  
   - `models/reward/models/head_v2.py` (lip/real/value í—¤ë“œ)
5) **í•™ìŠµ ë£¨í”„**  
   - `trainer/faceformer/trainer.py`ì—ì„œ sup loss + RL(actor/critic) ì¡°í•© í•™ìŠµ
6) **í…ŒìŠ¤íŠ¸**  
   - ê°™ì€ íŠ¸ë ˆì´ë„ˆì—ì„œ style-dependent í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
7) **ì €ì¥**  
   - `checkpoints/{wandb_name}/best.pt` ë“±ì— ëª¨ë¸/í—¤ë“œ ì €ì¥
##  1. Main Workflow Summary (`python main.py`)
ëª¨ë¸ì„ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ íŒŒì´í”„ë¼ì¸ì´ ì§„í–‰ë©ë‹ˆë‹¤.

Config ë¡œë“œ â†’ ë°ì´í„° ì¤€ë¹„ â†’ Actor ëª¨ë¸ ì¶”ë¡  â†’ Reward í‰ê°€ â†’ RL í•™ìŠµ â†’ Validation/Test

ê° ê³¼ì •ì˜ ëª©ì ë§Œ ì„¤ëª…í•˜ë©° **êµ¬ì²´ì ì¸ êµ¬í˜„, ìˆ˜ì‹, ì°¨ì› ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**

---

# 2. ğŸ”§ Config & Environment Loading
- Hydra ê¸°ë°˜ ì„¤ì • ë¡œë”©
- ëª¨ë¸ ì¢…ë¥˜, ë°ì´í„°ì…‹ íƒ€ì…, í•™ìŠµ/í‰ê°€ ì˜µì…˜ì„ í¬í•¨í•œ high-level configuration
- ì‹¤ì œ training parameter, architecture detailì€ ë¹„ê³µê°œ

---

# 3. ğŸ§ Data Loader (Audio & Mesh Preparation)
ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

### í¬í•¨ ìš”ì†Œ
- **ìŒì„± ì‹ í˜¸**  
  - waveform â†’ ìŒì„± ì¸ì½”ë”ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” embeddingìœ¼ë¡œ ë³€í™˜
- **ë©œ ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§•**  
  - Reward ëª¨ë¸ì—ì„œ í’ˆì§ˆ í‰ê°€ì— ì°¸ê³ ë˜ëŠ” ë³´ì¡° ì˜¤ë””ì˜¤ í‘œí˜„
- **Template Mesh**  
  - í•œ ì–¼êµ´ templateì— ëŒ€í•´ displacementë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹
- **Ground Truth Mesh Sequence**  
  - time-aligned mesh ì‹œí€€ìŠ¤
- **Subject Embedding**  
  - í™”ì ì¡°ê±´ ë¶€ì—¬(ì›í•« or ì„ë² ë”©)

### ë¹„ê³µê°œ ìš”ì†Œ
- ë°ì´í„° ì°¨ì› ë° ë‚´ë¶€ ì „ì²˜ë¦¬ ë¡œì§
- wav2vec/mesh loader ë“±ì˜ êµ¬ì²´ êµ¬í˜„

---

# 4. ğŸ§‘â€ğŸ« Actor Model (Face Animation Generator)
Actor ëª¨ë¸ì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ëª¨ë¸ ì—­í• 
- ìŒì„± ì¸ì½”ë”ê°€ ì¶”ì¶œí•œ speech embeddingê³¼  
  template mesh Â· subject ì •ë³´ ë“±ì„ ê²°í•©í•˜ì—¬  
  **íƒ€ì„ë¼ì¸ì— ë”°ë¥¸ 3D ì–¼êµ´ ë©”ì‰¬ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤.
- deterministic / stochastic ë‘ ê°€ì§€ ëª¨ë“œë¡œ ì‹¤í–‰ ê°€ëŠ¥

### ë¹„ê³µê°œ(ì—°êµ¬ ë³´í˜¸) ì²˜ë¦¬
- ì¸ì½”ë” êµ¬ì¡°, ì°¨ì›, attention/bias êµ¬ì¡°, normalization ë°©ì‹
- mesh representation ì°¨ì›
- distribution ê¸°ë°˜ sampling ê³µì‹
- loss functionì˜ êµ¬ì²´ì ì¸ ì¡°í•© ë° ê³„ì‚° ê³¼ì •

---

# 5. â­ Reward Model (Freezeëœ í’ˆì§ˆ í‰ê°€ ë„¤íŠ¸ì›Œí¬)
í•™ìŠµ ì‹œ actorê°€ ìƒì„±í•œ meshë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ **ë³„ë„ì˜ í’ˆì§ˆ ì¸¡ì • ëª¨ë¸**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ê¸°ëŠ¥
- ì˜¤ë””ì˜¤â€“ë©”ì‰¬ ê°„ **lip-sync**, **realism**, **temporal consistency** ë“±ì„ ì¸¡ì •  
- freeze ìƒíƒœë¡œ ì‚¬ìš©ë˜ë©°, actor ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ rewardë¥¼ ì œê³µ

### ë¹„ê³µê°œ ì²˜ë¦¬
- backbone/score-head architecture  
- ì…ë ¥ clip í˜•ì‹, ì°¨ì›  
- score ê³„ì‚° ë°©ì‹  

---

# 6. ğŸ§  Reinforcement Learning Loop (High-Level Description Only)
ë³¸ í”„ë¡œì íŠ¸ëŠ” supervised lossì™€ reinforcement signalì„ í•¨ê»˜ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ì „ì²´ íë¦„
1) Actorê°€ ì˜ˆì¸¡ ë©”ì‰¬ ìƒì„±  
2) Reward ëª¨ë¸ì´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°  
3) Criticì´ ì˜ˆì¸¡ ì•ˆì •ì„±ì„ ë•ëŠ” ë°©í–¥ìœ¼ë¡œ í‰ê°€  
4) ActorëŠ” ë†’ì€ í’ˆì§ˆ ë°©í–¥ìœ¼ë¡œ ì—…ë°ì´íŠ¸  
5) Criticì€ rewardë¥¼ ë” ì˜ ì˜ˆì¸¡í•˜ë„ë¡ ì—…ë°ì´íŠ¸  
6) Supervised í•™ìŠµê³¼ RL ì‹ í˜¸ê°€ í•¨ê»˜ ìµœì¢… loss êµ¬ì„±

### ë¹„ê³µê°œ ì²˜ë¦¬
- advantage ê³„ì‚°ì‹  
- actor/critic loss ê³µì‹  
- weight/scale ê°’  
- log_prob ê¸°ë°˜ ì •ì±… ì—…ë°ì´íŠ¸ ë°©ì‹  

---

# 7. ğŸ§ª Validation
- deterministic ëª¨ë“œë¡œ meshë¥¼ ìƒì„±í•˜ì—¬ í’ˆì§ˆ ì§€í‘œë¥¼ ê¸°ë¡  
- LVEÂ·FDD ë“± ì¼ë¶€ ì§€í‘œëŠ” ë‚´ë¶€ referenceì— ì˜í•´ ê³„ì‚°ë˜ë‚˜ ê³µê°œ ë²”ìœ„ ìµœì†Œí™”

---

# 8. ğŸ§« Test / Inference (Demo Version)
- best checkpointê°€ ì£¼ì–´ì§ˆ ê²½ìš° ì „ì²´ subject ì¡°ê±´ì—ì„œ ë©”ì‰¬ ìƒì„±  
- ê²°ê³¼ëŠ” .npy ë˜ëŠ” .obj ë“± ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ì €ì¥ ê°€ëŠ¥  
- public repoì—ëŠ” checkpointê°€ í¬í•¨ë˜ì§€ ì•Šìœ¼ë©°, demoìš© dummy predictorë§Œ ì œê³µë¨

---

# ğŸš« í¬í•¨ë˜ì§€ ì•ŠëŠ” í•­ëª© (Important)
ë³¸ ê³µê°œ ë²„ì „ì—ëŠ” ì•„ë˜ íŒŒì¼/êµ¬í˜„ì´ ì ˆëŒ€ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

- ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ weight (*.pt, *.pth)
- wav2vec ê¸°ë°˜ ìŒì„± ì¸ì½”ë” êµ¬í˜„
- mesh reconstruction/decoder ë‚´ë¶€ êµ¬ì¡°
- reward backbone ë° score head ìƒì„¸ êµ¬ì¡°
- reinforcement learning ê³µì‹, weighting, optimizer ì„¸ë¶€ ë¡œì§
- ë°ì´í„°ì…‹(wav, mel, vertices, template, mask)
- mask index, facial region mapping ë“± research-critical ì •ë³´
- ë…¼ë¬¸ êµ¬í˜„ê³¼ ì§ì ‘ ì—°ê²°ë˜ëŠ” ì°¨ì›/ìˆ˜ì‹/ì•Œê³ ë¦¬ì¦˜

---

## ğŸ“ Repository Structure (Demo Skeleton)
```
RL-VOCASET/
â”œâ”€â”€ pycache/
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ configs/
â”‚ â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ trainer/
â”‚ â””â”€â”€ config.yaml
â”œâ”€â”€ dataset/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ faceformer/
â”‚ â””â”€â”€ reward/
â”œâ”€â”€ src/
â”œâ”€â”€ trainer/
â”œâ”€â”€ utils/
â”œâ”€â”€ vocaset/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py 
â”œâ”€â”€ README.md
â”œâ”€â”€ render.py
â””â”€â”€ reward_score.py
```


```bash
- `main.py` : Hydra ì—”íŠ¸ë¦¬. config ì½ê³  ë°ì´í„°ë¡œë”/ëª¨ë¸/ë¦¬ì›Œë“œ/íŠ¸ë ˆì´ë„ˆ ê°ì²´ë¥¼ ì—®ì–´ train/test ì‹¤í–‰.
- `dataset/dataloader_style.py` : VOCASET ìŠ¤íƒ€ì¼ ë°ì´í„° ë¡œë” ì¸í„°í˜ì´ìŠ¤.
- `models/faceformer/model.py` : FaceFormer ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤(ì˜¤ë””ì˜¤ â†’ ë©”ì‰¬).
- `models/wav2vec.py` : Wav2Vec2 ì˜¤ë””ì˜¤ ì¸ì½”ë” ë˜í¼ ì¸í„°í˜ì´ìŠ¤.
- `models/reward/models/modeling.py` : SpeechMeshTransformer ë°±ë³¸ ì¸í„°í˜ì´ìŠ¤.
- `models/reward/models/head_v2.py` : Reward/critic í—¤ë“œ ì¸í„°í˜ì´ìŠ¤.
- `trainer/faceformer/trainer.py` : í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë§Œ ë‚¨ê¸´ íŠ¸ë ˆì´ë„ˆ.
- `src/utils.py` : ê³µìš© ìœ í‹¸(ë¡œê¹… ë“±).
```




###ğŸ“Œ Notes for Reviewers / Collaborators

* ë³¸ ë¬¸ì„œëŠ” ì—°êµ¬ íŒŒì´í”„ë¼ì¸ ì„¤ëª…ìš© ë¬¸ì„œì´ë©°,
ì‹¤ì œ ëª¨ë¸ì„ ì¬í˜„í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

* ìš”ì²­ ì‹œ full versionì€ private ì €ì¥ì†Œ ë° ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œë§Œ ê³µìœ ë©ë‹ˆë‹¤.

* ë³¸ repoëŠ” í•™ìŠµ/í‰ê°€ ì‹¤í–‰ì´ ë¶ˆê°€ëŠ¥í•˜ë©°, êµ¬ì¡° ì´í•´ì™€ ë°ëª¨ ëª©ì ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```bash
### 1) ğŸ”§ Config ë¡œë“œ (Hydra)
 - configs/config.yaml ë¶ˆëŸ¬ì˜¤ê¸°
 - defaults:
     model: faceformer
     dataset: style
     trainer: faceformer
 - cfg.train / cfg.test í”Œë˜ê·¸ì— ë”°ë¼ í•™ìŠµÂ·í‰ê°€ ì‹¤í–‰


### 2) ë°ì´í„° ë¡œë”© â€” dataset/dataloader_style.py
 -------------------------------------------------
- WAV ë¡œë“œ â†’ Wav2Vec2Processor ì…ë ¥ê°’ ìƒì„±
audio: (T_audio, )

- Mel íŠ¹ì§•(rep_audio_mel) â€” Reward ëª¨ë¸ìš©
rep_audio_mel: (T_clip, 1, 20, 128)

- Template mesh
template: (5023, 3) â†’ flatten â†’ (15069,)

- GT vertex ì‹œí€€ìŠ¤ (2í”„ë ˆì„ ìƒ˜í”Œë§ ì ìš©)
vertice: (seq_len, 15069)

- Subject one-hot
one_hot_train:     (num_speakers,)
one_hot_val_test:  (num_speakers_all, num_speakers)

- DataLoader ë°°ì¹˜ (batch=1)
batch_audio:   (1, T_audio)
batch_vertice: (1, seq_len, 15069)
batch_template:(1, 15069)
batch_onehot:  (1, num_speakers)
batch_rep_mel: rep_audio_mel ê·¸ëŒ€ë¡œ


### 3) Actor Model (FaceFormer) â€” models/faceformer/model.py
 -----------------------------------------------------------
- Audio Encoder
wav2vec2 â†’ (1, T_audio', 768) â†’ Linear â†’ (1, T_audio', 64)

- Transformer Decoder ì…ë ¥:
 - template displacement
 - style embedding(one_hot)
 - PPE, temporal bias ë“± í¬í•¨

- ì¶œë ¥:
vertice_mu:     (1, seq_len, 15069)     # mean
vertice_sample: (1, seq_len, 15069)     # stochastic modeì¼ ë•Œ
dist: Normal(Î¼,Ïƒ)                       # log_prob ê³„ì‚°ìš©

- Supervised Loss:
sup_loss = MSE(pred, GT)


### 4) Reward Backbone (ê³ ì •) â€” SpeechMeshTransformer
 ---------------------------------------------------
- ì…ë ¥:
mesh_clip: (B, 5, 15069)
mel_clip:  (B, 1, 20, 128)

- ì¶œë ¥ ì„ë² ë”©:
vertex_feat: (B, 512)
audio_feat:  (B, 512)

- ckpt ë¡œë“œ í›„ freeze, eval ëª¨ë“œ.


### 5) Score Head â€” head_v2.py
 --------------------------------
- ì…ë ¥:
concat_feat: (B, 512 + 512)

- ì¶œë ¥:
lip_score:  (B,)    # sigmoid
real_score: (B,)    # sigmoid
value:      (B,)    # critic V(s)

 head ckptëŠ” í•™ìŠµ ëŒ€ìƒ (requires_grad=True)


### 6) í•™ìŠµ ë£¨í”„ â€” trainer/faceformer/trainer.py::train
 ------------------------------------------------------

 (1) Actor forward
vertice_mu, vertice_sample, sup_loss

 (2) Reward ê³„ì‚°
 rep_audio_mel â†’ 5í”„ë ˆì„ ë‹¨ìœ„ ìŠ¬ë¼ì´ë”© â†’ backbone â†’ head
lip, real, value = mean over clips

reward    = (lip + real) * reward_scale
advantage = reward - value

actor_loss  = -advantage * mean(log_prob(sample))     # stochasticì¸ ê²½ìš°
critic_loss = (reward - value) ** 2

total_loss = sup_loss \
           + actor_weight  * actor_loss \
           + critic_weight * critic_loss

 Optimizer: Actor + Head ì—…ë°ì´íŠ¸


### 7) Validation
 ------------------------------------------------------
 - Actor deterministic forward
 - LVE(mouth vertex error) ê³„ì‚°
 - best ì„±ëŠ¥ ì‹œ ckpt ì €ì¥:
     checkpoints/<wandb_name>/best.pt
     checkpoints/<wandb_name>/best_head.pt


### 8) Test â€” trainer/faceformer/trainer.py::test
 ------------------------------------------------------
 - best ckpt ë¡œë“œ
 - ëª¨ë“  subject one-hot ì¡°ê±´ë³„ë¡œ ì˜ˆì¸¡ mesh npy ì €ì¥:
   checkpoints/<wandb_name>/styledependant/results/*.npy
 - LVE / FDD ê³„ì‚° ì¶œë ¥
 - style-independent ëª¨ë“œ: ëª¨ë“  one-hot í‰ê· ê°’ ì‚¬ìš©



## í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²ƒ
- ì‹¤ì œ í•™ìŠµ/ì¶”ë¡  êµ¬í˜„ ìƒì„¸, RL/Reward ë‚´ë¶€ ë¡œì§
- ì²´í¬í¬ì¸íŠ¸(.pt), ë°ì´í„°(wav, mel npy, vertices npy, templates, masks)

## ì‹¤ì œ ë°ì´í„°/ì²´í¬í¬ì¸íŠ¸ë¥¼ ì“¸ ê²½ìš° í•„ìš”í•œ ê²½ë¡œ (ì°¸ê³ ìš©)
 ì˜¤ë””ì˜¤: `vocaset/wav/`  
- ë©œ ìŠ¤í™íŠ¸ëŸ¼: `vocaset/wav_npy/`  
- ë©”ì‰¬ GT: `vocaset/vertices_npy/`  
- í…œí”Œë¦¿/ë§ˆìŠ¤í¬: `vocaset/templates.pkl`, `vocaset/FLAME_masks.pkl`  
- ë¦¬ì›Œë“œ ë°±ë³¸/í—¤ë“œ ckpt: `checkpoints/reward/model_loss.pth`, `checkpoints/reward/v4_best.pt`  
ë°ëª¨ ë¦¬í¬ì—ëŠ” ìœ„ íŒŒì¼ì´ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

```




